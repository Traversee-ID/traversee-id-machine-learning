{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!wget https://tmpfiles.org/dl/1497621/final.xlsx-sheet1.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4umh6tW3YY8d",
        "outputId": "deea8005-5550-4252-d70d-3e0a62b29845"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-06-04 14:41:07--  https://tmpfiles.org/dl/1497621/final.xlsx-sheet1.csv\n",
            "Resolving tmpfiles.org (tmpfiles.org)... 172.67.195.247, 104.21.21.16, 2606:4700:3036::ac43:c3f7, ...\n",
            "Connecting to tmpfiles.org (tmpfiles.org)|172.67.195.247|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 634583 (620K) [text/plain]\n",
            "Saving to: ‘final.xlsx-sheet1.csv’\n",
            "\n",
            "final.xlsx-sheet1.c 100%[===================>] 619.71K   539KB/s    in 1.2s    \n",
            "\n",
            "2023-06-04 14:41:10 (539 KB/s) - ‘final.xlsx-sheet1.csv’ saved [634583/634583]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install shortuuid\n",
        "!pip install schedule"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rGG_SCdKZcX1",
        "outputId": "c0498707-96c0-46ec-d502-5fd6a892fc85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting shortuuid\n",
            "  Downloading shortuuid-1.0.11-py3-none-any.whl (10 kB)\n",
            "Installing collected packages: shortuuid\n",
            "Successfully installed shortuuid-1.0.11\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting schedule\n",
            "  Downloading schedule-1.2.0-py2.py3-none-any.whl (11 kB)\n",
            "Installing collected packages: schedule\n",
            "Successfully installed schedule-1.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import random\n",
        "import shortuuid\n",
        "\n",
        "def generate_dataset(file_name):\n",
        "    # Load the CSV file into a pandas DataFrame\n",
        "    df = pd.read_csv(file_name)\n",
        "    df['itemID'] = [shortuuid.uuid() for _ in range(len(df))]\n",
        "\n",
        "    # Now you can work with the DataFrame 'df'\n",
        "    df = df[['itemID', 'description', 'category', 'city']]\n",
        "\n",
        "    # Your JSON data\n",
        "    json_data = [\n",
        "        {\n",
        "            \"userId\": \"user1\",\n",
        "            \"clickedItems\": random.choices(df['itemID'], k=5)\n",
        "        },\n",
        "        {\n",
        "            \"userId\": \"user2\",\n",
        "            \"clickedItems\": random.choices(df['itemID'], k=5)\n",
        "        },\n",
        "        {\n",
        "            \"userId\": \"user3\",\n",
        "            \"clickedItems\": random.choices(df['itemID'], k=5)\n",
        "        },\n",
        "        {\n",
        "            \"userId\": \"user4\",\n",
        "            \"clickedItems\": random.choices(df['itemID'], k=5)\n",
        "        },\n",
        "        {\n",
        "            \"userId\": \"user5\",\n",
        "            \"clickedItems\": random.choices(df['itemID'], k=5)\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    # Convert JSON to DataFrame\n",
        "    data = []\n",
        "    for user in json_data:\n",
        "        for item in user['clickedItems']:\n",
        "            data.append([user['userId'], item, 1])\n",
        "    df_user_clicked = pd.DataFrame(data, columns=['userID', 'itemID', 'clicked'])\n",
        "\n",
        "    # Create a DataFrame of all possible user-item pairs\n",
        "    all_users = df_user_clicked['userID'].unique()\n",
        "    all_items = df['itemID']\n",
        "\n",
        "    data_all = []\n",
        "    for user in all_users:\n",
        "        for item in all_items:\n",
        "            data_all.append([user, item])\n",
        "\n",
        "    df_all = pd.DataFrame(data_all, columns=['userID', 'itemID'])\n",
        "\n",
        "    # Merge df_all with df_items to add category, description, and other_attribute\n",
        "    df_all = pd.merge(df_all, df, on='itemID', how='left')\n",
        "\n",
        "    # Merge the user clicked data onto the DataFrame of all user-item pairs\n",
        "    df_final = pd.merge(df_all, df_user_clicked, how='left', on=['userID', 'itemID'], suffixes=('', '_user_clicked'))\n",
        "\n",
        "    # If the user has clicked the item, replace the 'clicked' value in df_all with the one from df_user_clicked\n",
        "    df_final['clicked'].fillna(0, inplace=True)  # fill NaNs with 0\n",
        "\n",
        "    return df_final\n",
        "\n",
        "df = generate_dataset('/content/final.xlsx-sheet1.csv')\n",
        "\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 9840
        },
        "id": "E-AnfN_gRs7O",
        "outputId": "776bad95-f320-46a0-e185-9aaa230a541b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     userID                  itemID  \\\n",
              "0     user1  mQ4pTnd9udxsJMC4PATtHD   \n",
              "1     user1  hhDEHww9chubphSJX7KBSw   \n",
              "2     user1  fK6zphmg8LpsHuPk8YahEJ   \n",
              "3     user1  a5jVc7yApYpffyC5CxqQdw   \n",
              "4     user1  4NNb3zZRkpZTcvHUPosDaB   \n",
              "...     ...                     ...   \n",
              "4490  user5  UDWGkLZf3Jxh9EFfTiMRgF   \n",
              "4491  user5  7XS3EFgSFqTDrTNr8CrzvA   \n",
              "4492  user5  UDQXLa4DZryR6a3B5fP9rd   \n",
              "4493  user5  jVvyQmqSnpmtEdhLJNEFyx   \n",
              "4494  user5  KEBMoDPq5CAYb8cHRMjSrK   \n",
              "\n",
              "                                            description       category  \\\n",
              "0     Air terjun Gitgit adalah air terjun yang terle...     Cagar Alam   \n",
              "1     Air terjun Tegenungan adalah air terjun yang t...     Cagar Alam   \n",
              "2     Alun-Alun Purworejo adalah sebuah alun-alun at...  Taman Hiburan   \n",
              "3     Bali Safari & Marine Park (BSMP) merupakan tem...  Taman Hiburan   \n",
              "4     Batu Secret Zoo merupakan tempat wisata dan ke...     Cagar Alam   \n",
              "...                                                 ...            ...   \n",
              "4490  Sejak diresmikan pada bulan Desember 2017, Atl...  Taman Hiburan   \n",
              "4491  Taman Hiburan Rakyat atau THR tentunya sudah t...  Taman Hiburan   \n",
              "4492  Air mancur menari atau dancing fountain juga a...  Taman Hiburan   \n",
              "4493  Taman Flora adalah salah satu taman kota di Su...  Taman Hiburan   \n",
              "4494  Gereja Katolik Kelahiran Santa Perawan Maria m...  Tempat Ibadah   \n",
              "\n",
              "           city  clicked  \n",
              "0      Buleleng      0.0  \n",
              "1      Denpasar      0.0  \n",
              "2     Purworejo      0.0  \n",
              "3       Gianyar      0.0  \n",
              "4          Batu      0.0  \n",
              "...         ...      ...  \n",
              "4490   Surabaya      0.0  \n",
              "4491   Surabaya      0.0  \n",
              "4492   Surabaya      0.0  \n",
              "4493   Surabaya      0.0  \n",
              "4494   Surabaya      0.0  \n",
              "\n",
              "[4495 rows x 6 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-01451151-8dab-4d4d-bbf3-4172649d554a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userID</th>\n",
              "      <th>itemID</th>\n",
              "      <th>description</th>\n",
              "      <th>category</th>\n",
              "      <th>city</th>\n",
              "      <th>clicked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>user1</td>\n",
              "      <td>mQ4pTnd9udxsJMC4PATtHD</td>\n",
              "      <td>Air terjun Gitgit adalah air terjun yang terle...</td>\n",
              "      <td>Cagar Alam</td>\n",
              "      <td>Buleleng</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>user1</td>\n",
              "      <td>hhDEHww9chubphSJX7KBSw</td>\n",
              "      <td>Air terjun Tegenungan adalah air terjun yang t...</td>\n",
              "      <td>Cagar Alam</td>\n",
              "      <td>Denpasar</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>user1</td>\n",
              "      <td>fK6zphmg8LpsHuPk8YahEJ</td>\n",
              "      <td>Alun-Alun Purworejo adalah sebuah alun-alun at...</td>\n",
              "      <td>Taman Hiburan</td>\n",
              "      <td>Purworejo</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>user1</td>\n",
              "      <td>a5jVc7yApYpffyC5CxqQdw</td>\n",
              "      <td>Bali Safari &amp; Marine Park (BSMP) merupakan tem...</td>\n",
              "      <td>Taman Hiburan</td>\n",
              "      <td>Gianyar</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>user1</td>\n",
              "      <td>4NNb3zZRkpZTcvHUPosDaB</td>\n",
              "      <td>Batu Secret Zoo merupakan tempat wisata dan ke...</td>\n",
              "      <td>Cagar Alam</td>\n",
              "      <td>Batu</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4490</th>\n",
              "      <td>user5</td>\n",
              "      <td>UDWGkLZf3Jxh9EFfTiMRgF</td>\n",
              "      <td>Sejak diresmikan pada bulan Desember 2017, Atl...</td>\n",
              "      <td>Taman Hiburan</td>\n",
              "      <td>Surabaya</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4491</th>\n",
              "      <td>user5</td>\n",
              "      <td>7XS3EFgSFqTDrTNr8CrzvA</td>\n",
              "      <td>Taman Hiburan Rakyat atau THR tentunya sudah t...</td>\n",
              "      <td>Taman Hiburan</td>\n",
              "      <td>Surabaya</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4492</th>\n",
              "      <td>user5</td>\n",
              "      <td>UDQXLa4DZryR6a3B5fP9rd</td>\n",
              "      <td>Air mancur menari atau dancing fountain juga a...</td>\n",
              "      <td>Taman Hiburan</td>\n",
              "      <td>Surabaya</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4493</th>\n",
              "      <td>user5</td>\n",
              "      <td>jVvyQmqSnpmtEdhLJNEFyx</td>\n",
              "      <td>Taman Flora adalah salah satu taman kota di Su...</td>\n",
              "      <td>Taman Hiburan</td>\n",
              "      <td>Surabaya</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4494</th>\n",
              "      <td>user5</td>\n",
              "      <td>KEBMoDPq5CAYb8cHRMjSrK</td>\n",
              "      <td>Gereja Katolik Kelahiran Santa Perawan Maria m...</td>\n",
              "      <td>Tempat Ibadah</td>\n",
              "      <td>Surabaya</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4495 rows × 6 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-01451151-8dab-4d4d-bbf3-4172649d554a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-01451151-8dab-4d4d-bbf3-4172649d554a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-01451151-8dab-4d4d-bbf3-4172649d554a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import random\n",
        "import numpy as np\n",
        "import pickle\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the data into a training set and a validation set\n",
        "df_train, df_val = train_test_split(df, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the maximum number of words in the texts to keep based on word frequency\n",
        "max_words = 500\n",
        "\n",
        "# Tokenizers\n",
        "tokenizer = Tokenizer(num_words=max_words, oov_token='<OOV>')\n",
        "tokenizer.fit_on_texts(df_train['description'])\n",
        "\n",
        "tokenizer_categories = Tokenizer(num_words=max_words, oov_token='<OOV>')\n",
        "tokenizer_categories.fit_on_texts(df_train['category'])\n",
        "\n",
        "tokenizer_other = Tokenizer(num_words=max_words, oov_token='<OOV>')\n",
        "tokenizer_other.fit_on_texts(df_train['city'])\n",
        "\n",
        "# Convert the texts to sequences\n",
        "description_sequences_train = tokenizer.texts_to_sequences(df_train['description'])\n",
        "description_sequences_val = tokenizer.texts_to_sequences(df_val['description'])\n",
        "\n",
        "categories_sequences_train = tokenizer_categories.texts_to_sequences(df_train['category'])\n",
        "categories_sequences_val = tokenizer_categories.texts_to_sequences(df_val['category'])\n",
        "\n",
        "other_sequences_train = tokenizer_other.texts_to_sequences(df_train['city'])\n",
        "other_sequences_val = tokenizer_other.texts_to_sequences(df_val['city'])\n",
        "\n",
        "# Pad the sequences so they are all the same length\n",
        "description_padded_train = pad_sequences(description_sequences_train, maxlen=max_words)\n",
        "description_padded_val = pad_sequences(description_sequences_val, maxlen=max_words)\n",
        "\n",
        "categories_padded_train = pad_sequences(categories_sequences_train, maxlen=max_words)\n",
        "categories_padded_val = pad_sequences(categories_sequences_val, maxlen=max_words)\n",
        "\n",
        "other_padded_train = pad_sequences(other_sequences_train, maxlen=max_words)\n",
        "other_padded_val = pad_sequences(other_sequences_val, maxlen=max_words)\n",
        "\n",
        "# Custom Label Encoding for user_id and item_id\n",
        "user_encoder = LabelEncoder()\n",
        "item_encoder = LabelEncoder()\n",
        "\n",
        "encoded_user_ids_train = user_encoder.fit_transform(df_train['userID'])\n",
        "encoded_item_ids_train = item_encoder.fit_transform(df_train['itemID'])\n",
        "\n",
        "encoded_user_ids_val = user_encoder.transform(df_val['userID'])\n",
        "encoded_item_ids_val = item_encoder.transform(df_val['itemID'])\n",
        "\n",
        "labels_train = df_train['clicked']\n",
        "labels_val = df_val['clicked']\n",
        "\n",
        "# Build the model\n",
        "user_input = layers.Input(shape=(1,), name='user')\n",
        "item_input = layers.Input(shape=(1,), name='item')\n",
        "description_input = layers.Input(shape=(max_words,), name='description')\n",
        "category_input = layers.Input(shape=(max_words,), name='category')\n",
        "other_input = layers.Input(shape=(max_words,), name='other')\n",
        "\n",
        "user_embedding = layers.Embedding(input_dim=len(user_encoder.classes_), output_dim=50)(user_input)\n",
        "item_embedding = layers.Embedding(input_dim=len(item_encoder.classes_), output_dim=50)(item_input)\n",
        "description_embedding = layers.Embedding(input_dim=max_words, output_dim=50)(description_input)\n",
        "category_embedding = layers.Embedding(input_dim=max_words, output_dim=50)(category_input)\n",
        "other_embedding = layers.Embedding(input_dim=max_words, output_dim=50)(other_input)\n",
        "\n",
        "user_embedding = layers.Flatten()(user_embedding)\n",
        "item_embedding = layers.Flatten()(item_embedding)\n",
        "description_embedding = layers.GlobalAveragePooling1D()(description_embedding)\n",
        "category_embedding = layers.GlobalAveragePooling1D()(category_embedding)\n",
        "other_embedding = layers.GlobalAveragePooling1D()(other_embedding)\n",
        "\n",
        "concatenated = layers.Concatenate()([user_embedding, item_embedding, description_embedding, category_embedding, other_embedding])\n",
        "\n",
        "dense1 = layers.Dense(128, activation='relu')(concatenated)\n",
        "dense2 = layers.Dense(64, activation='relu')(dense1)\n",
        "out = layers.Dense(1, activation='sigmoid')(dense2)\n",
        "\n",
        "model = tf.keras.Model(inputs=[user_input, item_input, description_input, category_input, other_input], outputs=out)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit([encoded_user_ids_train, encoded_item_ids_train, description_padded_train, categories_padded_train, other_padded_train], labels_train, epochs=10, validation_data=([encoded_user_ids_val, encoded_item_ids_val, description_padded_val, categories_padded_val, other_padded_val], labels_val))\n",
        "\n",
        "# Save the model, label encoders, and tokenizers for future use\n",
        "model.save('recommendation_model.h5')\n",
        "np.save('user_encoder_classes.npy', user_encoder.classes_)\n",
        "np.save('item_encoder_classes.npy', item_encoder.classes_)\n",
        "with open('tokenizer.pickle', 'wb') as handle:\n",
        "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "with open('tokenizer_categories.pickle', 'wb') as handle:\n",
        "    pickle.dump(tokenizer_categories, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "with open('tokenizer_other.pickle', 'wb') as handle:\n",
        "    pickle.dump(tokenizer_other, handle, protocol=pickle.HIGHEST_PROTOCOL)\n"
      ],
      "metadata": {
        "id": "8s_RDtv6iS_6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e93cda74-7d74-4ec0-d041-678e948d0735"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "113/113 [==============================] - 4s 16ms/step - loss: 0.1286 - accuracy: 0.9853 - val_loss: 0.0462 - val_accuracy: 0.9922\n",
            "Epoch 2/10\n",
            "113/113 [==============================] - 2s 21ms/step - loss: 0.0303 - accuracy: 0.9950 - val_loss: 0.0521 - val_accuracy: 0.9922\n",
            "Epoch 3/10\n",
            "113/113 [==============================] - 1s 12ms/step - loss: 0.0251 - accuracy: 0.9950 - val_loss: 0.0576 - val_accuracy: 0.9922\n",
            "Epoch 4/10\n",
            "113/113 [==============================] - 1s 12ms/step - loss: 0.0147 - accuracy: 0.9950 - val_loss: 0.0661 - val_accuracy: 0.9922\n",
            "Epoch 5/10\n",
            "113/113 [==============================] - 1s 12ms/step - loss: 0.0127 - accuracy: 0.9950 - val_loss: 0.0806 - val_accuracy: 0.9922\n",
            "Epoch 6/10\n",
            "113/113 [==============================] - 1s 12ms/step - loss: 0.0122 - accuracy: 0.9950 - val_loss: 0.0885 - val_accuracy: 0.9922\n",
            "Epoch 7/10\n",
            "113/113 [==============================] - 1s 12ms/step - loss: 0.0120 - accuracy: 0.9950 - val_loss: 0.0886 - val_accuracy: 0.9922\n",
            "Epoch 8/10\n",
            "113/113 [==============================] - 1s 12ms/step - loss: 0.0121 - accuracy: 0.9950 - val_loss: 0.0958 - val_accuracy: 0.9922\n",
            "Epoch 9/10\n",
            "113/113 [==============================] - 1s 11ms/step - loss: 0.0119 - accuracy: 0.9950 - val_loss: 0.0977 - val_accuracy: 0.9922\n",
            "Epoch 10/10\n",
            "113/113 [==============================] - 2s 17ms/step - loss: 0.0117 - accuracy: 0.9950 - val_loss: 0.1030 - val_accuracy: 0.9922\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import schedule\n",
        "import time\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "class Recommender:\n",
        "    def __init__(self, model_path, user_encoder_path, item_encoder_path, tokenizer_path, tokenizer_categories_path, tokenizer_other_path, df, max_words):\n",
        "        self.model_path = model_path\n",
        "        self.user_encoder_path = user_encoder_path\n",
        "        self.item_encoder_path = item_encoder_path\n",
        "        self.tokenizer_path = tokenizer_path\n",
        "        self.tokenizer_categories_path = tokenizer_categories_path\n",
        "        self.tokenizer_other_path = tokenizer_other_path\n",
        "        self.df = df\n",
        "        self.max_words = max_words\n",
        "        self.reload_model()\n",
        "\n",
        "    def reload_model(self):\n",
        "        self.model = tf.keras.models.load_model(self.model_path)\n",
        "\n",
        "        self.user_encoder = LabelEncoder()\n",
        "        self.user_encoder.classes_ = np.load(self.user_encoder_path, allow_pickle=True)\n",
        "\n",
        "        self.item_encoder = LabelEncoder()\n",
        "        self.item_encoder.classes_ = np.load(self.item_encoder_path, allow_pickle=True)\n",
        "\n",
        "        with open(self.tokenizer_path, 'rb') as handle:\n",
        "            self.tokenizer = pickle.load(handle)\n",
        "\n",
        "        with open(self.tokenizer_categories_path, 'rb') as handle:\n",
        "            self.tokenizer_categories = pickle.load(handle)\n",
        "\n",
        "        with open(self.tokenizer_other_path, 'rb') as handle:\n",
        "            self.tokenizer_other = pickle.load(handle)\n",
        "\n",
        "    def predict(self, new_user_id):\n",
        "        if new_user_id not in self.user_encoder.classes_:\n",
        "            print(\"New user detected. Assigning random existing user for prediction.\")\n",
        "            new_user_id = np.random.choice(self.user_encoder.classes_)\n",
        "\n",
        "        all_item_ids = self.df['itemID'].unique().tolist()\n",
        "        all_categories = []\n",
        "        all_descriptions = []\n",
        "        all_other_attributes = []\n",
        "\n",
        "        for item_id in all_item_ids:\n",
        "            item_data = self.df[self.df['itemID'] == item_id].iloc[0]\n",
        "            all_categories.append(item_data['category'])\n",
        "            all_descriptions.append(item_data['description'])\n",
        "            all_other_attributes.append(item_data['city'])\n",
        "\n",
        "        encoded_new_user_id = self.user_encoder.transform([new_user_id]*len(all_item_ids))\n",
        "        encoded_all_item_ids = self.item_encoder.transform(all_item_ids)\n",
        "\n",
        "        description_sequences = self.tokenizer.texts_to_sequences(all_descriptions)\n",
        "        description_padded = pad_sequences(description_sequences, maxlen=self.max_words)\n",
        "\n",
        "        category_sequences = self.tokenizer_categories.texts_to_sequences(all_categories)\n",
        "        category_padded = pad_sequences(category_sequences, maxlen=self.max_words)\n",
        "\n",
        "        other_sequences = self.tokenizer_other.texts_to_sequences(all_other_attributes)\n",
        "        other_padded = pad_sequences(other_sequences, maxlen=self.max_words)\n",
        "\n",
        "        predictions = self.model.predict([encoded_new_user_id, encoded_all_item_ids, description_padded, category_padded, other_padded])\n",
        "        top_10_indices = np.argsort(predictions[:, 0])[-10:]\n",
        "\n",
        "        print(\"Top 10 recommendations for\", new_user_id, \"are:\")\n",
        "        for index in reversed(top_10_indices):\n",
        "            print(f'Item: {all_item_ids[index]}, predicted click probability: {predictions[index][0]}')\n",
        "\n",
        "rec = Recommender('recommendation_model.h5', 'user_encoder_classes.npy', 'item_encoder_classes.npy', 'tokenizer.pickle', 'tokenizer_categories.pickle', 'tokenizer_other.pickle', df, 500)\n",
        "\n",
        "def job():\n",
        "    rec.reload_model()\n",
        "\n",
        "# Schedule the task every day at 12am\n",
        "schedule.every().day.at(\"00:00\").do(job)\n",
        "\n",
        "#while True:\n",
        "#    schedule.run_pending()\n",
        "#    time.sleep(1)\n",
        "\n",
        "rec.predict(\"budiman\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q-pAQv9yqz-X",
        "outputId": "5934702d-af3a-4a9b-892c-29809fc1b691"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New user detected. Assigning random existing user for prediction.\n",
            "29/29 [==============================] - 0s 4ms/step\n",
            "Top 10 recommendations for user3 are:\n",
            "Item: MfycC6ChryNPF2XKeAtKqK, predicted click probability: 0.41684412956237793\n",
            "Item: QihJsHybdCifWhYEaDrN4e, predicted click probability: 0.41548898816108704\n",
            "Item: 2Dh2DUZFjCy25EZY3beC9Q, predicted click probability: 0.36379942297935486\n",
            "Item: ZS6YuaPVNA4uk7ffprNSed, predicted click probability: 0.3419346809387207\n",
            "Item: ZQPYb4H3taRQenNPVQXpmF, predicted click probability: 0.3332783281803131\n",
            "Item: HXuNAen7yRW6Szi5jxEkLv, predicted click probability: 0.32979080080986023\n",
            "Item: TagejZv7ne7spsGyexwHUG, predicted click probability: 0.32564276456832886\n",
            "Item: JoVmAMTrF3G3NM59SFNfrp, predicted click probability: 0.32380205392837524\n",
            "Item: RFXgufSyhWfhNSdFRrctk4, predicted click probability: 0.3212657570838928\n",
            "Item: JL4SZnPx35AbR8stb2NsDC, predicted click probability: 0.3175490200519562\n"
          ]
        }
      ]
    }
  ]
}