{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!wget https://tmpfiles.org/dl/1499103/final.xlsx-sheet1.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4umh6tW3YY8d",
        "outputId": "fdd8e94d-09b5-4fd4-f222-77a51220ffd6"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-06-05 03:16:56--  https://tmpfiles.org/dl/1499103/final.xlsx-sheet1.csv\n",
            "Resolving tmpfiles.org (tmpfiles.org)... 172.67.195.247, 104.21.21.16, 2606:4700:3030::6815:1510, ...\n",
            "Connecting to tmpfiles.org (tmpfiles.org)|172.67.195.247|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 634583 (620K) [text/plain]\n",
            "Saving to: ‘final.xlsx-sheet1.csv’\n",
            "\n",
            "final.xlsx-sheet1.c 100%[===================>] 619.71K  --.-KB/s    in 0.1s    \n",
            "\n",
            "2023-06-05 03:16:56 (6.22 MB/s) - ‘final.xlsx-sheet1.csv’ saved [634583/634583]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install shortuuid\n",
        "!pip install schedule"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rGG_SCdKZcX1",
        "outputId": "961048d8-8f0f-4fb5-c1cb-1c11e4fe0343"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting shortuuid\n",
            "  Downloading shortuuid-1.0.11-py3-none-any.whl (10 kB)\n",
            "Installing collected packages: shortuuid\n",
            "Successfully installed shortuuid-1.0.11\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting schedule\n",
            "  Downloading schedule-1.2.0-py2.py3-none-any.whl (11 kB)\n",
            "Installing collected packages: schedule\n",
            "Successfully installed schedule-1.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import random\n",
        "import shortuuid\n",
        "\n",
        "def generate_dataset(file_name):\n",
        "    # Load the CSV file into a pandas DataFrame\n",
        "    df = pd.read_csv(file_name)\n",
        "    df['itemID'] = [shortuuid.uuid() for _ in range(len(df))]\n",
        "\n",
        "    # Now you can work with the DataFrame 'df'\n",
        "    df = df[['itemID', 'description', 'category', 'city']]\n",
        "\n",
        "    # Your JSON data\n",
        "    json_data = [\n",
        "        {\n",
        "            \"userId\": \"user1\",\n",
        "            \"clickedItems\": random.choices(df['itemID'], k=50)\n",
        "        },\n",
        "        {\n",
        "            \"userId\": \"user2\",\n",
        "            \"clickedItems\": random.choices(df['itemID'], k=50)\n",
        "        },\n",
        "        {\n",
        "            \"userId\": \"user3\",\n",
        "            \"clickedItems\": random.choices(df['itemID'], k=50)\n",
        "        },\n",
        "        {\n",
        "            \"userId\": \"user4\",\n",
        "            \"clickedItems\": random.choices(df['itemID'], k=50)\n",
        "        },\n",
        "        {\n",
        "            \"userId\": \"user5\",\n",
        "            \"clickedItems\": random.choices(df['itemID'], k=50)\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    # Convert JSON to DataFrame\n",
        "    data = []\n",
        "    for user in json_data:\n",
        "        for item in user['clickedItems']:\n",
        "            data.append([user['userId'], item, 1])\n",
        "    df_user_clicked = pd.DataFrame(data, columns=['userID', 'itemID', 'clicked'])\n",
        "\n",
        "    # Create a DataFrame of all possible user-item pairs\n",
        "    all_users = df_user_clicked['userID'].unique()\n",
        "    all_items = df['itemID']\n",
        "\n",
        "    data_all = []\n",
        "    for user in all_users:\n",
        "        for item in all_items:\n",
        "            data_all.append([user, item])\n",
        "\n",
        "    df_all = pd.DataFrame(data_all, columns=['userID', 'itemID'])\n",
        "\n",
        "    # Merge df_all with df_items to add category, description, and other_attribute\n",
        "    df_all = pd.merge(df_all, df, on='itemID', how='left')\n",
        "\n",
        "    # Merge the user clicked data onto the DataFrame of all user-item pairs\n",
        "    df_final = pd.merge(df_all, df_user_clicked, how='left', on=['userID', 'itemID'], suffixes=('', '_user_clicked'))\n",
        "\n",
        "    # If the user has clicked the item, replace the 'clicked' value in df_all with the one from df_user_clicked\n",
        "    df_final['clicked'].fillna(0, inplace=True)  # fill NaNs with 0\n",
        "\n",
        "    return df_final\n",
        "\n",
        "df = generate_dataset('/content/final.xlsx-sheet1.csv')\n",
        "\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468
        },
        "id": "E-AnfN_gRs7O",
        "outputId": "5d006b54-362b-4a62-e30b-9ed5ffbd9c01"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     userID                  itemID  \\\n",
              "0     user1  3TTYRU8bnMw2dx8gRWyXjP   \n",
              "1     user1  FRvNNt3ekX6N7Z82ispjnG   \n",
              "2     user1  LJRcJdz6nXs2or2Vh32K6n   \n",
              "3     user1  9WHhAhPoqoAjToH7HwHxAd   \n",
              "4     user1  9cA56ytodmECruyHvAwS7Z   \n",
              "...     ...                     ...   \n",
              "4495  user5  HVU3Z2RAeDKABnWZzHqLNc   \n",
              "4496  user5  2QyjoWCxSEMK4yTfwzM7sH   \n",
              "4497  user5  9RGDnb7QXWWViH5d47p5tx   \n",
              "4498  user5  mYmtqbN6oRYEvnzNubmRY7   \n",
              "4499  user5  nHnG4g7eWpZUtkH2ioPJfU   \n",
              "\n",
              "                                            description       category  \\\n",
              "0     Air terjun Gitgit adalah air terjun yang terle...     Cagar Alam   \n",
              "1     Air terjun Tegenungan adalah air terjun yang t...     Cagar Alam   \n",
              "2     Alun-Alun Purworejo adalah sebuah alun-alun at...  Taman Hiburan   \n",
              "3     Bali Safari & Marine Park (BSMP) merupakan tem...  Taman Hiburan   \n",
              "4     Batu Secret Zoo merupakan tempat wisata dan ke...     Cagar Alam   \n",
              "...                                                 ...            ...   \n",
              "4495  Sejak diresmikan pada bulan Desember 2017, Atl...  Taman Hiburan   \n",
              "4496  Taman Hiburan Rakyat atau THR tentunya sudah t...  Taman Hiburan   \n",
              "4497  Air mancur menari atau dancing fountain juga a...  Taman Hiburan   \n",
              "4498  Taman Flora adalah salah satu taman kota di Su...  Taman Hiburan   \n",
              "4499  Gereja Katolik Kelahiran Santa Perawan Maria m...  Tempat Ibadah   \n",
              "\n",
              "           city  clicked  \n",
              "0      Buleleng      0.0  \n",
              "1      Denpasar      0.0  \n",
              "2     Purworejo      0.0  \n",
              "3       Gianyar      0.0  \n",
              "4          Batu      0.0  \n",
              "...         ...      ...  \n",
              "4495   Surabaya      0.0  \n",
              "4496   Surabaya      0.0  \n",
              "4497   Surabaya      0.0  \n",
              "4498   Surabaya      0.0  \n",
              "4499   Surabaya      0.0  \n",
              "\n",
              "[4500 rows x 6 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-caeab37b-5698-4f2a-8f57-90e09253aad5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userID</th>\n",
              "      <th>itemID</th>\n",
              "      <th>description</th>\n",
              "      <th>category</th>\n",
              "      <th>city</th>\n",
              "      <th>clicked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>user1</td>\n",
              "      <td>3TTYRU8bnMw2dx8gRWyXjP</td>\n",
              "      <td>Air terjun Gitgit adalah air terjun yang terle...</td>\n",
              "      <td>Cagar Alam</td>\n",
              "      <td>Buleleng</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>user1</td>\n",
              "      <td>FRvNNt3ekX6N7Z82ispjnG</td>\n",
              "      <td>Air terjun Tegenungan adalah air terjun yang t...</td>\n",
              "      <td>Cagar Alam</td>\n",
              "      <td>Denpasar</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>user1</td>\n",
              "      <td>LJRcJdz6nXs2or2Vh32K6n</td>\n",
              "      <td>Alun-Alun Purworejo adalah sebuah alun-alun at...</td>\n",
              "      <td>Taman Hiburan</td>\n",
              "      <td>Purworejo</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>user1</td>\n",
              "      <td>9WHhAhPoqoAjToH7HwHxAd</td>\n",
              "      <td>Bali Safari &amp; Marine Park (BSMP) merupakan tem...</td>\n",
              "      <td>Taman Hiburan</td>\n",
              "      <td>Gianyar</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>user1</td>\n",
              "      <td>9cA56ytodmECruyHvAwS7Z</td>\n",
              "      <td>Batu Secret Zoo merupakan tempat wisata dan ke...</td>\n",
              "      <td>Cagar Alam</td>\n",
              "      <td>Batu</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4495</th>\n",
              "      <td>user5</td>\n",
              "      <td>HVU3Z2RAeDKABnWZzHqLNc</td>\n",
              "      <td>Sejak diresmikan pada bulan Desember 2017, Atl...</td>\n",
              "      <td>Taman Hiburan</td>\n",
              "      <td>Surabaya</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4496</th>\n",
              "      <td>user5</td>\n",
              "      <td>2QyjoWCxSEMK4yTfwzM7sH</td>\n",
              "      <td>Taman Hiburan Rakyat atau THR tentunya sudah t...</td>\n",
              "      <td>Taman Hiburan</td>\n",
              "      <td>Surabaya</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4497</th>\n",
              "      <td>user5</td>\n",
              "      <td>9RGDnb7QXWWViH5d47p5tx</td>\n",
              "      <td>Air mancur menari atau dancing fountain juga a...</td>\n",
              "      <td>Taman Hiburan</td>\n",
              "      <td>Surabaya</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4498</th>\n",
              "      <td>user5</td>\n",
              "      <td>mYmtqbN6oRYEvnzNubmRY7</td>\n",
              "      <td>Taman Flora adalah salah satu taman kota di Su...</td>\n",
              "      <td>Taman Hiburan</td>\n",
              "      <td>Surabaya</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4499</th>\n",
              "      <td>user5</td>\n",
              "      <td>nHnG4g7eWpZUtkH2ioPJfU</td>\n",
              "      <td>Gereja Katolik Kelahiran Santa Perawan Maria m...</td>\n",
              "      <td>Tempat Ibadah</td>\n",
              "      <td>Surabaya</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4500 rows × 6 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-caeab37b-5698-4f2a-8f57-90e09253aad5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-caeab37b-5698-4f2a-8f57-90e09253aad5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-caeab37b-5698-4f2a-8f57-90e09253aad5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import random\n",
        "import numpy as np\n",
        "import pickle\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the data into a training set and a validation set\n",
        "df_train, df_val = train_test_split(df, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the maximum number of words in the texts to keep based on word frequency\n",
        "max_words = 500\n",
        "\n",
        "# Tokenizers\n",
        "tokenizer = Tokenizer(num_words=max_words, oov_token='<OOV>')\n",
        "tokenizer.fit_on_texts(df_train['description'])\n",
        "\n",
        "tokenizer_categories = Tokenizer(num_words=max_words, oov_token='<OOV>')\n",
        "tokenizer_categories.fit_on_texts(df_train['category'])\n",
        "\n",
        "tokenizer_other = Tokenizer(num_words=max_words, oov_token='<OOV>')\n",
        "tokenizer_other.fit_on_texts(df_train['city'])\n",
        "\n",
        "# Convert the texts to sequences\n",
        "description_sequences_train = tokenizer.texts_to_sequences(df_train['description'])\n",
        "description_sequences_val = tokenizer.texts_to_sequences(df_val['description'])\n",
        "\n",
        "categories_sequences_train = tokenizer_categories.texts_to_sequences(df_train['category'])\n",
        "categories_sequences_val = tokenizer_categories.texts_to_sequences(df_val['category'])\n",
        "\n",
        "other_sequences_train = tokenizer_other.texts_to_sequences(df_train['city'])\n",
        "other_sequences_val = tokenizer_other.texts_to_sequences(df_val['city'])\n",
        "\n",
        "# Pad the sequences so they are all the same length\n",
        "description_padded_train = pad_sequences(description_sequences_train, maxlen=max_words)\n",
        "description_padded_val = pad_sequences(description_sequences_val, maxlen=max_words)\n",
        "\n",
        "categories_padded_train = pad_sequences(categories_sequences_train, maxlen=max_words)\n",
        "categories_padded_val = pad_sequences(categories_sequences_val, maxlen=max_words)\n",
        "\n",
        "other_padded_train = pad_sequences(other_sequences_train, maxlen=max_words)\n",
        "other_padded_val = pad_sequences(other_sequences_val, maxlen=max_words)\n",
        "\n",
        "# Custom Label Encoding for user_id and item_id\n",
        "user_encoder = LabelEncoder()\n",
        "item_encoder = LabelEncoder()\n",
        "\n",
        "encoded_user_ids_train = user_encoder.fit_transform(df_train['userID'])\n",
        "encoded_item_ids_train = item_encoder.fit_transform(df_train['itemID'])\n",
        "\n",
        "encoded_user_ids_val = user_encoder.transform(df_val['userID'])\n",
        "encoded_item_ids_val = item_encoder.transform(df_val['itemID'])\n",
        "\n",
        "labels_train = df_train['clicked']\n",
        "labels_val = df_val['clicked']\n",
        "\n",
        "# Build the model\n",
        "user_input = layers.Input(shape=(1,), name='user')\n",
        "item_input = layers.Input(shape=(1,), name='item')\n",
        "description_input = layers.Input(shape=(max_words,), name='description')\n",
        "category_input = layers.Input(shape=(max_words,), name='category')\n",
        "other_input = layers.Input(shape=(max_words,), name='other')\n",
        "\n",
        "user_embedding = layers.Embedding(input_dim=len(user_encoder.classes_), output_dim=50)(user_input)\n",
        "item_embedding = layers.Embedding(input_dim=len(item_encoder.classes_), output_dim=50)(item_input)\n",
        "description_embedding = layers.Embedding(input_dim=max_words, output_dim=50)(description_input)\n",
        "category_embedding = layers.Embedding(input_dim=max_words, output_dim=50)(category_input)\n",
        "other_embedding = layers.Embedding(input_dim=max_words, output_dim=50)(other_input)\n",
        "\n",
        "user_embedding = layers.Flatten()(user_embedding)\n",
        "item_embedding = layers.Flatten()(item_embedding)\n",
        "description_embedding = layers.GlobalAveragePooling1D()(description_embedding)\n",
        "category_embedding = layers.GlobalAveragePooling1D()(category_embedding)\n",
        "other_embedding = layers.GlobalAveragePooling1D()(other_embedding)\n",
        "\n",
        "concatenated = layers.Concatenate()([user_embedding, item_embedding, description_embedding, category_embedding, other_embedding])\n",
        "\n",
        "dense1 = layers.Dense(128, activation='relu')(concatenated)\n",
        "dense2 = layers.Dense(64, activation='relu')(dense1)\n",
        "out = layers.Dense(1, activation='sigmoid')(dense2)\n",
        "\n",
        "model = tf.keras.Model(inputs=[user_input, item_input, description_input, category_input, other_input], outputs=out)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit([encoded_user_ids_train, encoded_item_ids_train, description_padded_train, categories_padded_train, other_padded_train], labels_train, epochs=10, validation_data=([encoded_user_ids_val, encoded_item_ids_val, description_padded_val, categories_padded_val, other_padded_val], labels_val))\n",
        "\n",
        "# Save the model, label encoders, and tokenizers for future use\n",
        "model.save('recommendation_model.h5')\n",
        "np.save('user_encoder_classes.npy', user_encoder.classes_)\n",
        "np.save('item_encoder_classes.npy', item_encoder.classes_)\n",
        "with open('tokenizer.pickle', 'wb') as handle:\n",
        "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "with open('tokenizer_categories.pickle', 'wb') as handle:\n",
        "    pickle.dump(tokenizer_categories, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "with open('tokenizer_other.pickle', 'wb') as handle:\n",
        "    pickle.dump(tokenizer_other, handle, protocol=pickle.HIGHEST_PROTOCOL)\n"
      ],
      "metadata": {
        "id": "8s_RDtv6iS_6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "490d852a-43d3-43e3-ba2a-696a524437f4"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "113/113 [==============================] - 3s 11ms/step - loss: 0.2627 - accuracy: 0.9442 - val_loss: 0.2112 - val_accuracy: 0.9456\n",
            "Epoch 2/10\n",
            "113/113 [==============================] - 1s 9ms/step - loss: 0.1919 - accuracy: 0.9442 - val_loss: 0.2283 - val_accuracy: 0.9456\n",
            "Epoch 3/10\n",
            "113/113 [==============================] - 1s 9ms/step - loss: 0.1407 - accuracy: 0.9442 - val_loss: 0.2811 - val_accuracy: 0.9456\n",
            "Epoch 4/10\n",
            "113/113 [==============================] - 1s 9ms/step - loss: 0.1240 - accuracy: 0.9442 - val_loss: 0.3560 - val_accuracy: 0.9456\n",
            "Epoch 5/10\n",
            "113/113 [==============================] - 1s 13ms/step - loss: 0.1212 - accuracy: 0.9442 - val_loss: 0.3817 - val_accuracy: 0.9456\n",
            "Epoch 6/10\n",
            "113/113 [==============================] - 1s 10ms/step - loss: 0.1222 - accuracy: 0.9442 - val_loss: 0.3774 - val_accuracy: 0.9456\n",
            "Epoch 7/10\n",
            "113/113 [==============================] - 1s 9ms/step - loss: 0.1195 - accuracy: 0.9444 - val_loss: 0.3868 - val_accuracy: 0.9444\n",
            "Epoch 8/10\n",
            "113/113 [==============================] - 1s 9ms/step - loss: 0.1143 - accuracy: 0.9475 - val_loss: 0.4284 - val_accuracy: 0.9422\n",
            "Epoch 9/10\n",
            "113/113 [==============================] - 1s 10ms/step - loss: 0.1014 - accuracy: 0.9533 - val_loss: 0.4586 - val_accuracy: 0.9433\n",
            "Epoch 10/10\n",
            "113/113 [==============================] - 1s 9ms/step - loss: 0.0864 - accuracy: 0.9556 - val_loss: 0.5208 - val_accuracy: 0.9411\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import schedule\n",
        "import time\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "class Recommender:\n",
        "    def __init__(self, model_path, user_encoder_path, item_encoder_path, tokenizer_path, tokenizer_categories_path, tokenizer_other_path, df, max_words):\n",
        "        self.model_path = model_path\n",
        "        self.user_encoder_path = user_encoder_path\n",
        "        self.item_encoder_path = item_encoder_path\n",
        "        self.tokenizer_path = tokenizer_path\n",
        "        self.tokenizer_categories_path = tokenizer_categories_path\n",
        "        self.tokenizer_other_path = tokenizer_other_path\n",
        "        self.df = df\n",
        "        self.max_words = max_words\n",
        "        self.reload_model()\n",
        "\n",
        "    def reload_model(self):\n",
        "        self.model = tf.keras.models.load_model(self.model_path)\n",
        "\n",
        "        self.user_encoder = LabelEncoder()\n",
        "        self.user_encoder.classes_ = np.load(self.user_encoder_path, allow_pickle=True)\n",
        "\n",
        "        self.item_encoder = LabelEncoder()\n",
        "        self.item_encoder.classes_ = np.load(self.item_encoder_path, allow_pickle=True)\n",
        "\n",
        "        with open(self.tokenizer_path, 'rb') as handle:\n",
        "            self.tokenizer = pickle.load(handle)\n",
        "\n",
        "        with open(self.tokenizer_categories_path, 'rb') as handle:\n",
        "            self.tokenizer_categories = pickle.load(handle)\n",
        "\n",
        "        with open(self.tokenizer_other_path, 'rb') as handle:\n",
        "            self.tokenizer_other = pickle.load(handle)\n",
        "\n",
        "    def predict(self, new_user_id):\n",
        "        all_item_ids = self.df['itemID'].unique().tolist()\n",
        "        all_categories = []\n",
        "        all_descriptions = []\n",
        "        all_other_attributes = []\n",
        "\n",
        "        for item_id in all_item_ids:\n",
        "            item_data = self.df[self.df['itemID'] == item_id].iloc[0]\n",
        "            all_categories.append(item_data['category'])\n",
        "            all_descriptions.append(item_data['description'])\n",
        "            all_other_attributes.append(item_data['city'])\n",
        "\n",
        "        if new_user_id not in self.user_encoder.classes_:\n",
        "            print(\"New user detected. Assigning random existing user for prediction.\")\n",
        "            new_user_id = np.random.choice(self.user_encoder.classes_)\n",
        "\n",
        "        encoded_new_user_id = self.user_encoder.transform([new_user_id]*len(all_item_ids))\n",
        "        encoded_all_item_ids = self.item_encoder.transform(all_item_ids)\n",
        "\n",
        "        description_sequences = self.tokenizer.texts_to_sequences(all_descriptions)\n",
        "        description_padded = pad_sequences(description_sequences, maxlen=self.max_words)\n",
        "\n",
        "        category_sequences = self.tokenizer_categories.texts_to_sequences(all_categories)\n",
        "        category_padded = pad_sequences(category_sequences, maxlen=self.max_words)\n",
        "\n",
        "        other_sequences = self.tokenizer_other.texts_to_sequences(all_other_attributes)\n",
        "        other_padded = pad_sequences(other_sequences, maxlen=self.max_words)\n",
        "\n",
        "        predictions = self.model.predict([encoded_new_user_id, encoded_all_item_ids, description_padded, category_padded, other_padded])\n",
        "        top_10_indices = np.argsort(predictions[:, 0])[-10:]\n",
        "\n",
        "        print(\"Top 10 recommendations for\", new_user_id, \"are:\")\n",
        "        for index in reversed(top_10_indices):\n",
        "            print(f'Item: {all_item_ids[index]}, predicted click probability: {predictions[index][0]}')\n",
        "\n",
        "    # Dummy implementation\n",
        "    def recommend_popular_items(self):\n",
        "        print(\"Here are some popular items\")\n",
        "\n",
        "\n",
        "\n",
        "rec = Recommender('recommendation_model.h5', 'user_encoder_classes.npy', 'item_encoder_classes.npy', 'tokenizer.pickle', 'tokenizer_categories.pickle', 'tokenizer_other.pickle', df, 500)\n",
        "\n",
        "def job():\n",
        "    rec.reload_model()\n",
        "\n",
        "# Schedule the task every day at 12am\n",
        "schedule.every().day.at(\"00:00\").do(job)\n",
        "\n",
        "#while True:\n",
        "#    schedule.run_pending()\n",
        "#    time.sleep(1)\n",
        "\n",
        "rec.predict(\"budiman\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q-pAQv9yqz-X",
        "outputId": "a921ab26-497d-44e0-d87f-7fdc11a9c21d"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New user detected. Assigning random existing user for prediction.\n",
            "29/29 [==============================] - 0s 3ms/step\n",
            "Top 10 recommendations for user3 are:\n",
            "Item: P8Hs4z8WJaYxNYMeQ56QVX, predicted click probability: 0.6135902404785156\n",
            "Item: HVU3Z2RAeDKABnWZzHqLNc, predicted click probability: 0.6119400262832642\n",
            "Item: Dz2gmzdhxgGjmcg8dPdt6R, predicted click probability: 0.596519410610199\n",
            "Item: S4ELmMr3KkfJtzQG7wNeLu, predicted click probability: 0.5855777859687805\n",
            "Item: RgmQr8fpKQ7yFfcYE6iPpG, predicted click probability: 0.5715683698654175\n",
            "Item: 4HSauRSDAnkntYQhiPU9Da, predicted click probability: 0.5561433434486389\n",
            "Item: Kr5JWkeCbcKsda42T5Ybwz, predicted click probability: 0.5489989519119263\n",
            "Item: WxRitkumUWJdPkL9vykHSm, predicted click probability: 0.5320135354995728\n",
            "Item: 4nqpDRmYff64cFeGuaYiWn, predicted click probability: 0.5265135765075684\n",
            "Item: apKjahSWG3Yd2j5kSvVvtv, predicted click probability: 0.5114524960517883\n"
          ]
        }
      ]
    }
  ]
}